{"cells":[{"cell_type":"markdown","source":["## Automating Table Shortcuts in Microsoft Fabric for Unified Data Strategy in OneLake\n","**by Jesus Lopez Martin - https://www.syntax.es - November 2024**\n","\n","This Python script demonstrates how to automate the creation of shortcuts for tables between a source Workspace and Lakehouse and a destination Workspace and Lakehouse in Microsoft Fabric. It aligns with the \"single source of truth\" strategy in OneLake and supports the Medallion architecture, simplifying data access and management across workspaces. By leveraging the Microsoft Fabric APIs and the semantic-link-labs library, this approach helps streamline data integration and reduce redundancy.\n","\n","**Key Benefits:**\n","- Centralized Data Access: This script supports the \"single source of truth\" strategy by enabling seamless access to tables across workspaces and Lakehouses without data duplication.\n","- Simplified Management: Automates the creation of shortcuts, reducing manual effort and operational overhead.\n","- Medallion Architecture Support: Facilitates the creation of Bronze, Silver, and Gold layers in Microsoft Fabric by linking data across Lakehouses.\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4e036e1e-9411-4178-b60f-43a418133fed"},{"cell_type":"code","source":["%pip install semantic-link-labs --q"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a400e4a6-22c0-46a0-8c08-a2b44da3413c"},{"cell_type":"code","source":["import sempy_labs.lakehouse as lakehouse\n","\n","# Step 1: Get all tables from the source Lakehouse\n","source_workspace = \"TEST Source Workspace\"\n","source_lakehouse = \"Source_Lakehouse\"\n","destination_workspace = \"TEST Destination Workspace\"\n","destination_lakehouse = \"Destination_Lakehouse\"\n","\n","# Retrieve tables as a DataFrame\n","df_tables = lakehouse.get_lakehouse_tables(\n","    lakehouse=source_lakehouse, \n","    workspace=source_workspace\n",")\n","\n","# Step 2: Loop through the DataFrame and create shortcuts for each table\n","for table_name in df_tables['Table Name']:  # Iterate directly over the 'name' column\n","    lakehouse.create_shortcut_onelake(\n","        table_name=table_name,\n","        source_lakehouse=source_lakehouse,\n","        source_workspace=source_workspace,\n","        destination_lakehouse=destination_lakehouse,\n","        destination_workspace=destination_workspace,\n","        shortcut_name=table_name  # Using the same name for the shortcut\n","    )\n","    print(f'Successfully created shortcut for table: {table_name}')\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"37b15002-7ce7-448b-bc88-6d5d1466071f"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","language":"Python","display_name":"Synapse PySpark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{},"environment":{}}},"nbformat":4,"nbformat_minor":5}